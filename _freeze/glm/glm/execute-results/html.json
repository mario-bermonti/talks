{
  "hash": "ced3b79d754a8fb46bbbc0f669e855c9",
  "result": {
    "markdown": "---\ntitle: \"General Linear Model (GLM)\"\nauthor: \"Mario E. Bermonti-PÃ©rez, MA, PhD\"\nformat: \n    revealjs:\n        incremental: true \n        chalkboard: true \n        theme: dark\n        center: true\n    # pdf:\n    #     echo: false\n---\n\n::: {.cell}\n\n:::\n\n\n## Objectives\n:::{.center}\n- Understand the basic concepts of the GLM\n- Understand the usefulness of the GLM\n- Understand how the GLM underlies most stats methods\n- Understand the basic process of applying the GLM\n::::\n\n# GLM basics\n::: {.notes}\nWhat is the GLM?\n:::\n\n## Form\n![](./assets/glm.png)\n\n## Examples\n:::: {.columns}\n::: {.column width=\"40%\"}\n![](./assets/glm.png)\n:::\n\n::: {.column width=\"60%\"}\n- Attention -> WM\n- Art -> Sustained attention\n- ADHD -> Innatention\n- Celiac disease -> Processing speed\n- Intervention -> Selective attention\n- Musical training -> EF\n:::\n::::\n::: {.notes}\nFamiliar? - Regression\n:::\n\n## Form\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n![](./assets/glm.png)\n:::\n\n::: {.column width=\"50%\"}\n- ğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘œğ‘šğ‘’ = (ğ‘ƒğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘œğ‘Ÿ)\n\n- ğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘œğ‘šğ‘’ = (ğ‘ƒğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘œğ‘Ÿ) + error\n\n- Y =(ğ›½) + ğœ€\n\n- Y = (ğ›½0 + ğ›½1) + ğœ€\n\n- Y = (ğ›½0 + ğ›½1 + ğ›½2) + ğœ€\n:::\n::::\n\n## Study effects\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n![](./assets/glm.png)\n:::\n\n::: {.column width=\"50%\"}\n- Relationship\n- Difference between groups\n:::\n::::\n::: {.notes}\nWhat does a difference mean?\n:::\n\n## Usefulness\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n![](./assets/glm.png)\n:::\n\n::: {.column width=\"50%\"}\n- Existence: statistical significance\n- Size: effect size, parameter\n:::\n::::\n\n# GLM with different variables\n\n## Lets see the variables\n\n## Phonological loop span\n## Ready?\n::: {.notes}\nVolunteer\n:::\n## 8\n## 4\n## 0\n## 3\n## 7\n## 1\n## 2\n\n## Numbers?\n::: {.notes}\n8 4 0 3 7 1 2\n:::\n\n## Selective attention\n## Ready?\n::: {.notes}\nStroop task\n\nBottom up, left to right\n:::\n\n## Go\n![](./assets/stroop.png)\n \n<!-- Sim data -->\n\n\n::: {.cell}\n\n:::\n\n\n# Back to GLM with different variables\n\n## First, there were data\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n::: {.notes}\nTip: 2 centers = 2 pops\n:::\n\n## Differences between 2 groups?\n\n## Process\n## Group by attentional level\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n## Estimate mean\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n::: {.notes}\nWhy the mean?\n:::\n\n## Estimate relationship (difference)\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n::: {.notes}\nCompare 2 means? - t-test\n\nLine?\n\nLine not in regression??\n:::\n\n## GLM form\n![](./assets/2groups.png)\n\n## GLM analysis\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = wm_span ~ group, data = data_2_groups)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.19530 -0.63041  0.05458  0.60334  2.42107 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            4.12750    0.09036   45.68   <2e-16 ***\ngroupnormal attention  5.01134    0.12779   39.22   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9036 on 198 degrees of freedom\nMultiple R-squared:  0.8859,\tAdjusted R-squared:  0.8854 \nF-statistic:  1538 on 1 and 198 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.notes}\nfamiliar output?\n:::\n\n## A step further...\n\n## Differences between 4 groups\n## Process\n\n::: {.cell}\n\n:::\n\n\n## Group by attentional level\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n## Estimate mean\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n## Estimate relationship (difference)\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n::: {.notes}\nCompare 4 means? - ANOVA\n\nLine?\n:::\n\n## GLM form\n![](./assets/4groups.png)\n\n## GLM form 2 vs 4 groups\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](./assets/4groups.png)\n:::\n\n::: {.column width=\"50%\"}\n![](./assets/2groups.png)\n:::\n::::\n::: {.notes}\nDifference?\n:::\n\n\n## GLM analysis\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = wm_span ~ group, data = data_4_groups)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.84184 -0.63680 -0.06289  0.59698  3.04514 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  3.00820    0.09759   30.82   <2e-16 ***\ngroupmild attention deficit  1.91735    0.13801   13.89   <2e-16 ***\ngroupnormal attention        3.95551    0.13801   28.66   <2e-16 ***\ngroupsuperior attention      8.03811    0.13801   58.24   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9759 on 396 degrees of freedom\nMultiple R-squared:  0.9041,\tAdjusted R-squared:  0.9034 \nF-statistic:  1244 on 3 and 396 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.notes}\nsevere deficit as baseline\n:::\n\n## A step further...\n\n# Numeric predictors\n\n## Attention and WM\n### Estimate relationship\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n::: {.notes}\ngraph type?\n:::\n\n## Estimate relationship line\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](glm_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n::: {.notes}\nRelationships 2 numeric variables? - Correlation/Regression\n:::\n\n## GLM form\n![](./assets/numvars.png)\n\n## GLM analysis\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = wm ~ attention, data = data_cont_vars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.5620 -0.9462  0.0568  0.9981  3.6676 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.90047    0.61286   3.101  0.00252 ** \nattention    0.12844    0.01513   8.491 2.25e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.574 on 98 degrees of freedom\nMultiple R-squared:  0.4238,\tAdjusted R-squared:  0.418 \nF-statistic: 72.09 on 1 and 98 DF,  p-value: 2.253e-13\n```\n:::\n:::\n\n\n## Summary of models\n:::: {.columns}\n::: {.column width=\"40%\"}\n![](./assets/glm.png){#general}\n:::\n\n::: {.column width=\"60%\"}\n::: {layout-nrow=1}\n<!-- ![](glm.png){#general}\n![](glm.png){#general}\n![](glm.png){#general} -->\n<img src=\"./assets/2groups.png\" />\n<img src=\"./assets/4groups.png\" />\n<img src=\"./assets/numvars.png\" />\n::: \n:::\n\n::::\n::: {.notes}    \nDifference?\n\nNumeric = More levels\n\nMore levels = More info\n:::\n\n# Closing\n## Conclusions\n- GLM underlies most stats methods\n- Simple but powerful idea\n- Use variables to predict variables\n- Effects = relationships, differences\n\n## Questions or Comments\n\n## Further resources\n- [Andy Field Lectures - YouTube](https://www.youtube.com/watch?v=7cSArk7tU4w&t=1634s)\n\n- Field, A. (2017). Discovering Statistics Using IBM SPSS Statistics (5th ed.). London: Sage Publications. Chapter 2.\n\n## Bonus\n::: {.nonincremental}\n:::: {.columns}\n::: {.column width=\"40%\"} \n- Always GLM\n:::\n\n::: {.column width=\"60%\"}\n![](./assets/glm_always.jpeg)\n:::\n::::\n:::\n\n## GLM subtypes\n![](./assets/glm_types.png)",
    "supporting": [
      "glm_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}